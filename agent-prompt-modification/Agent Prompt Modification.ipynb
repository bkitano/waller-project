{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents Prompt Modification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate an agent that changes the prompt of another agent. This would constitute a kind of quality intelligence improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an evaluator agent evaluates the performance of a task agent\n",
    "# the evaluator agent stores a prompt for a task agent in a file\n",
    "# the task agent performs a task and stores a transcript of its actions to a file\n",
    "# the evaluator reads the transcript and evaluates the task agent's performance\n",
    "# the evaluator decides how to change the task agent's prompt based on the performance\n",
    "# the task agent reads the new prompt and performs the task again"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to work on the 20_newsgroups dataset for classification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import SerpAPIWrapper\n",
    "from langchain.agents import AgentExecutor, OpenAIFunctionsAgent\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Type\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key=os.environ['SERPAPI_API_KEY'])\n",
    "llm = ChatOpenAI(model='gpt-3.5-turbo-0613', openai_api_key=os.environ['OPENAI_API_KEY'])\n",
    "\n",
    "class EvaluateSingleTranscriptToolInput(BaseModel):\n",
    "    task_agent_prompt: str = Field(description=\"The prompt used by the task agent to perform the task.\")\n",
    "    transcript: str = Field(description=\"The transcript of a task agent's actions.\")\n",
    "    correct_tag: str = Field(description=\"The correct tag for the task agent's actions.\")\n",
    "\n",
    "class EvaluateSingleTranscriptTool(BaseTool):\n",
    "    \"\"\"\n",
    "    This evaluates a single transcript of a task agent's actions. It tries to assess whether\n",
    "    the task agent's actions were successful or not. It could be a simple loss function, or\n",
    "    it could be a more complex function that tries to determine the cause of the task agent's\n",
    "    failure.\n",
    "    \"\"\"\n",
    "    name = \"transcript-evaluator\"\n",
    "    description = \"Evaluate the transcript of a task agent's actions.\"\n",
    "    args_schema: Type[BaseTool] = EvaluateSingleTranscriptToolInput\n",
    "\n",
    "    def _run(self, transcript: str, task_agent_prompt: str, correct_tag: str):\n",
    "        prompt = PromptTemplate(input_variables=[\n",
    "            'task_agent_prompt',\n",
    "            'transcript',\n",
    "            'correct_tag'\n",
    "        ], template=\"\"\"\n",
    "        You are an evaluator of AI agents. You review the diagnosed problem of an agent and decide how to change their prompts.\n",
    "        The task agent's original prompt was: {task_agent_prompt}\n",
    "        The task agent's transcript is: {transcript}\n",
    "        The correct tag for the task agent's actions is: {correct_tag}\n",
    "\n",
    "        Did this task agent perform the task correctly? If not, what was the cause of the task agent's failure?\n",
    "        \"\"\")\n",
    "\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        return chain.run({'task_agent_prompt': task_agent_prompt, 'transcript': transcript, 'correct_tag': correct_tag})\n",
    "    def _arun(self, transcript: str, prompt: str):\n",
    "        pass\n",
    "\n",
    "class ModifyPromptToolInput(BaseModel):\n",
    "\n",
    "    original_task_agent_prompt: str = Field(description=\"The original prompt used by the task agent to perform the task.\")\n",
    "    evaluation_notes: str = Field(description=\"The evaluation of the task agent's performance.\")\n",
    "\n",
    "class ModifyPromptTool(BaseTool):\n",
    "    \"\"\"\n",
    "    Seems like it's going to be limited if it can only modify the prompt based on a single transcript.\n",
    "    Probably the EvaluateTranscriptsTool needs to be able to evaluate multiple transcripts, then\n",
    "    come up with an abstraction for a common cause as to why the task agent failed, then modify the prompt\n",
    "    based on that abstraction.\n",
    "    \"\"\"\n",
    "    name = \"prompt-modifier\"\n",
    "    description = \"Modify the prompt of a task agent based on its performance.\"\n",
    "    args_schema: Type[BaseModel] = ModifyPromptToolInput\n",
    "    def _run(self, evaluation_notes: str, original_task_agent_prompt: str):\n",
    "        prompt = PromptTemplate(input_variables=[\n",
    "            'original_task_agent_prompt',\n",
    "            'evaluation_notes'\n",
    "        ], template=\"\"\"\n",
    "        You are an evaluator of AI agents. You review the diagnosed problem of an agent and decide how to change their prompts.\n",
    "        The task agent's original prompt: {original_task_agent_prompt}\n",
    "        The task agent's evaluation notes: {evaluation_notes}\n",
    "\n",
    "        You decide to change the task agent's prompt to:\n",
    "        \"\"\")\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        new_prompt = chain.run({'original_task_agent_prompt': original_task_agent_prompt, 'evaluation_notes': evaluation_notes})\n",
    "        \n",
    "        open('task_agent_prefix.txt', 'w').write(new_prompt)\n",
    "        return new_prompt\n",
    "\n",
    "    def _arun(self, evaluation_notes: str, original_task_agent_prompt: str):\n",
    "        pass\n",
    "\n",
    "tools = [\n",
    "    EvaluateSingleTranscriptTool(),\n",
    "    ModifyPromptTool()\n",
    "]\n",
    "\n",
    "evaluator_agent = OpenAIFunctionsAgent.from_llm_and_tools(\n",
    "    llm=llm, \n",
    "    tools=tools,\n",
    "    prefix=\"You are an evaluator of AI agents. You review task agents' transcripts and decide how to change their prompts.\",\n",
    "    verbose=True,\n",
    "    )\n",
    "\n",
    "evaluator_agent_executor = AgentExecutor.from_agent_and_tools(evaluator_agent, tools, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_agent_prefix = open('./task_agent_prefix.txt', 'r').read()\n",
    "\n",
    "class ClassifyArticleToolInput(BaseModel):\n",
    "    article: str = Field(description=\"The article to classify.\")\n",
    "\n",
    "class ClassifyArticleTool(BaseTool):\n",
    "    \"\"\"\n",
    "    This tool classifies an article based on its content.\n",
    "    \"\"\"\n",
    "    name = \"article-classifier\"\n",
    "    description = \"Classify an article based on its content.\"\n",
    "    args_schema: Type[BaseTool] = ClassifyArticleToolInput\n",
    "\n",
    "    def _run(self, article: str):\n",
    "        prompt = PromptTemplate(input_variables=['article'], template=\"\"\"\n",
    "                                You are a classifier of articles. You classify articles based on their content.\n",
    "                                The article you are classifying is: {article}\n",
    "                                You classify the article as:\n",
    "                                \"\"\")\n",
    "        chain = LLMChain(llm=llm, prompt=prompt)\n",
    "        return chain.run({'article': article})\n",
    "\n",
    "    def _arun(self, article: str):\n",
    "        pass\n",
    "\n",
    "task_agent_tools = [ClassifyArticleTool()]\n",
    "task_agent = OpenAIFunctionsAgent.from_llm_and_tools(\n",
    "    llm=llm,\n",
    "    tools=task_agent_tools,\n",
    "    prefix=task_agent_prefix,\n",
    "    verbose=True\n",
    "    )\n",
    "\n",
    "task_agent_executor = AgentExecutor.from_agent_and_tools(task_agent, task_agent_tools, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep 20_newsgroups dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep the 20_newsgroups dataset\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def get_data():\n",
    "    newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "    newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "    X_train = pd.DataFrame(newsgroups_train.data)\n",
    "    X_train.columns = ['text']\n",
    "    X_test = pd.DataFrame(newsgroups_test.data)\n",
    "    X_test.columns = ['text']\n",
    "    X_train['text'] = X_train['text'].apply(clean_text)\n",
    "    X_train['target'] = newsgroups_train.target\n",
    "    X_train['label'] = X_train['target'].apply(lambda x: newsgroups_train.target_names[x])\n",
    "    \n",
    "    X_test['text'] = X_test['text'].apply(clean_text)\n",
    "    X_test['target'] = newsgroups_test.target\n",
    "    X_test['label'] = X_test['target'].apply(lambda x: newsgroups_test.target_names[x])\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "X_train, X_test = get_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it together"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the task agent on an example article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `article-classifier` with `{'article': 'from lerxst wam umd edu where s my thing subject what car is this nntp posting host rac3 wam umd edu organization university of maryland college park lines 15 i was wondering if anyone out there could enlighten me on this car i saw the other day it was a 2 door sports car looked to be from the late 60s early 70s it was called a bricklin the doors were really small in addition the front bumper was separate from the rest of the body this is all i know if anyone can tellme a model name engine specs years of production where this car is made history or whatever info you have on this funky looking car please e mail thanks il brought to you by your neighborhood lerxst'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mThe article can be classified as \"Automotive\".\u001b[0m\u001b[32;1m\u001b[1;3mBased on the content of the article, it appears to be about a car. Specifically, the author is seeking information about a 2-door sports car called a Bricklin. The car is described as being from the late 60s or early 70s, with small doors and a separate front bumper. The author is interested in learning more about the model name, engine specifications, years of production, where the car is made, and its history. If anyone has any information about this car, the author requests that they email him.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `transcript-evaluator` with `{'task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'transcript': 'Based on the content of the article, it appears to be about a car. Specifically, the author is seeking information about a 2-door sports car called a Bricklin. The car is described as being from the late 60s or early 70s, with small doors and a separate front bumper. The author is interested in learning more about the model name, engine specifications, years of production, where the car is made, and its history. If anyone has any information about this car, the author requests that they email him.', 'correct_tag': 'rec.autos'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mYes, the task agent performed the task correctly. It correctly identified that the document is about a car and provided information about the specific car model mentioned in the document. The task agent also correctly identified the author's request for information about the car. The correct tag for the task agent's actions is rec.autos.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `transcript-evaluator` with `{'task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'transcript': 'Based on the content of the article, it appears to be about a car. Specifically, the author is seeking information about a 2-door sports car called a Bricklin. The car is described as being from the late 60s or early 70s, with small doors and a separate front bumper. The author is interested in learning more about the model name, engine specifications, years of production, where the car is made, and its history. If anyone has any information about this car, the author requests that they email him.', 'correct_tag': 'rec.autos'}`\n",
      "responded: {content}\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNo, the task agent did not perform the task correctly. The cause of the task agent's failure is that it provided a detailed description of the document instead of classifying it into a specific category.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `transcript-evaluator` with `{'task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'transcript': 'Based on the content of the article, it appears to be about a car. Specifically, the author is seeking information about a 2-door sports car called a Bricklin. The car is described as being from the late 60s or early 70s, with small doors and a separate front bumper. The author is interested in learning more about the model name, engine specifications, years of production, where the car is made, and its history. If anyone has any information about this car, the author requests that they email him.', 'correct_tag': 'rec.autos'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNo, the task agent did not perform the task correctly. The cause of the task agent's failure is that it did not classify the document correctly as being about a car.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `prompt-modifier` with `{'original_task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'evaluation_notes': 'The task agent correctly identified that the document is about a car and provided relevant information about the car model mentioned.'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mYou are a document classifier. Your task is to classify the document and provide relevant information about the car model mentioned, including its features, specifications, and any other relevant details.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `prompt-modifier` with `{'original_task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'evaluation_notes': \"The task agent correctly identified that the document is about a car and provided information about the specific car model mentioned in the document. The task agent also correctly identified the author's request for information about the car.\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mYou are a document classifier. Your task is to classify a document and provide information about the specific car model mentioned in the document. Additionally, you should identify any requests for information about the car made by the author.\u001b[0m\u001b[32;1m\u001b[1;3mThe prompt for the task agent can be modified to: \"You are a document classifier. Your task is to classify a document and provide information about the specific car model mentioned in the document. Additionally, you should identify any requests for information about the car made by the author.\" This modification takes into account the task agent's correct identification of the document being about a car and its understanding of the author's request for information about the car.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `article-classifier` with `{'article': 'from guykuo carson u washington edu guy kuo subject si clock poll final call summary final call for si clock reports keywords si acceleration clock upgrade article i d shelley 1qvfo9innc3s organization university of washington lines 11 nntp posting host carson u washington edu a fair number of brave souls who upgraded their si clock oscillator have shared their experiences for this poll please send a brief message detailing your experiences with the procedure top speed attained cpu rated speed add on cards and adapters heat sinks hour of usage per day floppy disk functionality with 800 and 1 4 m floppies are especially requested i will be summarizing in the next two days so please add to the network knowledge base if you have done the clock upgrade and haven t answered this poll thanks guy kuo guykuo u washington edu'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mThe article can be classified as a request for experiences and information regarding a clock upgrade for the SI (System Integration) clock oscillator.\u001b[0m\u001b[32;1m\u001b[1;3mThe article you provided is a request for experiences and information regarding a clock upgrade for the SI (System Integration) clock oscillator. The person who posted the article is asking for individuals who have upgraded their SI clock oscillator to share their experiences with the procedure, including details such as the top speed attained, CPU rated speed, add-on cards and adapters used, heat sinks, hours of usage per day, and floppy disk functionality with 800 and 1.4M floppies. The person intends to summarize the responses in the next two days and encourages those who have done the clock upgrade but haven't answered the poll to contribute to the network's knowledge base.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `transcript-evaluator` with `{'task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'transcript': \"The article you provided is a request for experiences and information regarding a clock upgrade for the SI (System Integration) clock oscillator. The person who posted the article is asking for individuals who have upgraded their SI clock oscillator to share their experiences with the procedure, including details such as the top speed attained, CPU rated speed, add-on cards and adapters used, heat sinks, hours of usage per day, and floppy disk functionality with 800 and 1.4M floppies. The person intends to summarize the responses in the next two days and encourages those who have done the clock upgrade but haven't answered the poll to contribute to the network's knowledge base.\", 'correct_tag': 'comp.sys.mac.hardware'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mBased on the given information, it is clear that the task agent did not perform the task correctly. The cause of the task agent's failure is that it misclassified the document. The document is related to a clock upgrade for the SI (System Integration) clock oscillator, which is specific to hardware, specifically comp.sys.mac.hardware. However, the task agent's original prompt was too generic and did not provide enough context for the agent to correctly classify the document.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `prompt-modifier` with `{'original_task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'evaluation_notes': 'The task agent misclassified the document because the original prompt was too generic. It did not provide enough context for the agent to correctly classify the document as related to a clock upgrade for the SI clock oscillator in the comp.sys.mac.hardware category.'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m\"You are a document classifier for technical documents. Your task is to classify a document related to a clock upgrade for the SI clock oscillator in the comp.sys.mac.hardware category. Provide the most accurate classification based on the content of the document.\"\u001b[0m\u001b[32;1m\u001b[1;3mI have modified the prompt for the task agent to provide more specific instructions for classifying documents related to a clock upgrade for the SI clock oscillator in the comp.sys.mac.hardware category. This should help the task agent better understand the task and improve its performance.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `article-classifier` with `{'article': 'from twillis ec ecn purdue edu thomas e willis subject pb questions organization purdue university engineering computer network distribution usa lines 36 well folks my mac plus finally gave up the ghost this weekend after starting life as a 512k way back in 1985 sooo i m in the market for a new machine a bit sooner than i intended to be i m looking into picking up a powerbook 160 or maybe 180 and have a bunch of questions that hopefully somebody can answer does anybody know any dirt on when the next round of powerbook introductions are expected i d heard the 185c was supposed to make an appearence this summer but haven t heard anymore on it and since i don t have access to macleak i was wondering if anybody out there had more info has anybody heard rumors about price drops to the powerbook line like the ones the duo s just went through recently what s the impression of the display on the 180 i could probably swing a 180 if i got the 80mb disk rather than the 120 but i don t really have a feel for how much better the display is yea it looks great in the store but is that all wow or is it really that good could i solicit some opinions of people who use the 160 and 180 day to day on if its worth taking the disk size and money hit to get the active display i realize this is a real subjective question but i ve only played around with the machines in a computer store breifly and figured the opinions of somebody who actually uses the machine daily might prove helpful how well does hellcats perform thanks a bunch in advance for any info if you could email i ll post a summary news reading time is at a premium with finals just around the corner tom willis twillis ecn purdue edu purdue electrical engineering convictions are more dangerous enemies of truth than lies f w nietzsche'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mTechnology/Computers\u001b[0m\u001b[32;1m\u001b[1;3mBased on the content of the article, it appears to be discussing questions and considerations related to purchasing a new computer, specifically a PowerBook 160 or 180. The article also mentions rumors about upcoming PowerBook introductions and potential price drops. Additionally, the author seeks opinions on the display quality and performance of the PowerBook models. The article concludes with a request for information on the performance of Hellcats.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `transcript-evaluator` with `{'task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'transcript': 'Based on the content of the article, it appears to be discussing questions and considerations related to purchasing a new computer, specifically a PowerBook 160 or 180. The article also mentions rumors about upcoming PowerBook introductions and potential price drops. Additionally, the author seeks opinions on the display quality and performance of the PowerBook models. The article concludes with a request for information on the performance of Hellcats.', 'correct_tag': 'comp.sys.mac.hardware'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNo, the task agent did not perform the task correctly. The cause of the task agent's failure is that it misclassified the document. Instead of correctly categorizing it as a document discussing questions and considerations related to purchasing a new computer, specifically a PowerBook 160 or 180, it should have been classified as comp.sys.mac.hardware.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `prompt-modifier` with `{'original_task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'evaluation_notes': 'The task agent misclassified the document. It should have been classified as comp.sys.mac.hardware.'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mYou are a document classifier. Your task is to classify a document. The document you are given is related to hardware and technology. Classify the document accordingly.\u001b[0m\u001b[32;1m\u001b[1;3mBased on the evaluation, it appears that the task agent misclassified the document. The correct tag for the task agent's actions should have been \"comp.sys.mac.hardware\". \n",
      "\n",
      "To improve the task agent's performance, the prompt can be modified to provide more specific instructions. Here is a modified prompt:\n",
      "\n",
      "\"You are a document classifier. Your task is to classify a document related to hardware and technology. Carefully analyze the content and classify the document accordingly. Provide the most appropriate tag for the document.\"\n",
      "\n",
      "By providing more context and specific instructions, it is expected that the task agent will be able to correctly classify the document in future attempts.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `article-classifier` with `{'article': 'from jgreen amber joe green subject re weitek p9000 organization harris computer systems division lines 14 distribution world nntp posting host amber ssd csd harris com x newsreader tin version 1 1 pl9 robert j c kyanko rob rjck uucp wrote abraxis iastate edu writes in article abraxis 734340159 class1 iastate edu anyone know about the weitek p9000 graphics chip as far as the low level stuff goes it looks pretty nice it s got this quadrilateral fill command that requires just the four points do you have weitek s address phone number i d like to get some information about this chip joe green harris corporation jgreen csd harris com computer systems division the only thing that really scares me is a person with no sense of humor jonathan winters'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mTechnology/Computers\u001b[0m\u001b[32;1m\u001b[1;3mThe article is classified as \"Technology/Computers\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `transcript-evaluator` with `{'task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'transcript': 'The article is classified as \"Technology/Computers\".', 'correct_tag': 'comp.graphics'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNo, the task agent did not perform the task correctly. The cause of the task agent's failure is that it incorrectly classified the document as \"Technology/Computers\" when the correct tag should have been \"comp.graphics\".\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `prompt-modifier` with `{'original_task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'evaluation_notes': 'The task agent incorrectly classified the document as \"Technology/Computers\". The correct tag should have been \"comp.graphics\".'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mYou are a document classifier. Your task is to correctly classify a document into different categories such as \"Technology/Computers\", \"comp.graphics\", and more.\u001b[0m\u001b[32;1m\u001b[1;3mBased on the evaluation of the task agent's performance, the prompt for the task agent can be modified to:\n",
      "\n",
      "\"You are a document classifier. Your task is to correctly classify a document into different categories such as 'Technology/Computers', 'comp.graphics', and more.\"\n",
      "\n",
      "This modified prompt emphasizes the need for the task agent to correctly classify the document and provides specific examples of categories to consider.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `article-classifier` with `{'article': 'from jcm head cfa harvard edu jonathan mcdowell subject re shuttle launch question organization smithsonian astrophysical observatory cambridge ma usa distribution sci lines 23 from article c5owcb n3p world std com by tombaker world std com tom a baker in article c5jlwx 4h9 1 cs cmu edu etrat ttacs1 ttu edu pack rat writes clear caution warning memory verify no unexpected errors i am wondering what an expected error might be sorry if this is a really dumb question but parity errors in memory or previously known conditions that were waivered yes that is an error but we already knew about it i d be curious as to what the real meaning of the quote is tom my understanding is that the expected errors are basically known bugs in the warning system software things are checked that don t have the right values in yet because they aren t set till after launch and suchlike rather than fix the code and possibly introduce new bugs they just tell the crew ok if you see a warning no 213 before liftoff ignore it jonathan'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mTechnology - discussing computer memory and software bugs\u001b[0m\u001b[32;1m\u001b[1;3mBased on the content of the article, it appears to be discussing computer memory and software bugs. Specifically, it mentions parity errors in memory and known bugs in the warning system software. The article also discusses the decision to not fix the code and instead inform the crew to ignore certain warnings before liftoff.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `transcript-evaluator` with `{'task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'transcript': 'Based on the content of the article, it appears to be discussing computer memory and software bugs. Specifically, it mentions parity errors in memory and known bugs in the warning system software. The article also discusses the decision to not fix the code and instead inform the crew to ignore certain warnings before liftoff.', 'correct_tag': 'sci.space'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mNo, the task agent did not perform the task correctly. The cause of the task agent's failure is that it did not classify the document correctly as \"sci.space.\" Instead, it focused on the content of the article discussing computer memory, software bugs, and a decision related to liftoff warnings.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `prompt-modifier` with `{'original_task_agent_prompt': 'You are a document classifier. Your task is to classify a document.', 'evaluation_notes': \"The task agent failed to correctly classify the document as 'sci.space.' The prompt needs to be modified to emphasize the correct classification.\"}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mYou are a document classifier. Your task is to correctly classify a document as either 'sci.space' or 'other.'\u001b[0m\u001b[32;1m\u001b[1;3mI have modified the prompt to emphasize the correct classification. The task agent prompt is now: \"You are a document classifier. Your task is to correctly classify a document as either 'sci.space' or 'other'.\" This modification should help the task agent understand the goal of the task better and improve its performance.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    sample = dict(X_train.iloc[i])\n",
    "    text = sample['text']\n",
    "    label = sample['label']\n",
    "\n",
    "    task_agent_output = task_agent_executor.run(text)\n",
    "\n",
    "    # generate a transcript of the task agent's actions for the evaluator agent\n",
    "    evaluator_agent_executor.run(f\"\"\"\n",
    "        This is the transcript of the task agent's actions: {task_agent_output}\n",
    "        The task agent's prompt was: {task_agent_prefix}\n",
    "        The correct tag for the task agent's actions is: \"{label}\"\n",
    "    \"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "So the evaluator being only able to run on a single example at a time is not good (overfitting). We'll want to batch transcript examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waller-project-_ugCvovn-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
